{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y= to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =    train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_object = MinMaxScaler()\n",
    "scaler_object.fit(X_train)\n",
    "\n",
    "scaled_X_train = scaler_object.transform(X_train)\n",
    "scaled_X_test = scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are ready to call the neural network model from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First create a sequential model and then add layers to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax')) ### Number of classes which are already in numpy format and 3 by 150 shape \n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "### lossis really about the problem pou are trying to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 1s - loss: 1.1475 - acc: 0.0500\n",
      "Epoch 2/150\n",
      " - 0s - loss: 1.1336 - acc: 0.2800\n",
      "Epoch 3/150\n",
      " - 0s - loss: 1.1204 - acc: 0.3400\n",
      "Epoch 4/150\n",
      " - 0s - loss: 1.1087 - acc: 0.3400\n",
      "Epoch 5/150\n",
      " - 0s - loss: 1.0953 - acc: 0.3400\n",
      "Epoch 6/150\n",
      " - 0s - loss: 1.0840 - acc: 0.3400\n",
      "Epoch 7/150\n",
      " - 0s - loss: 1.0742 - acc: 0.3500\n",
      "Epoch 8/150\n",
      " - 0s - loss: 1.0667 - acc: 0.3500\n",
      "Epoch 9/150\n",
      " - 0s - loss: 1.0610 - acc: 0.3500\n",
      "Epoch 10/150\n",
      " - 0s - loss: 1.0566 - acc: 0.3300\n",
      "Epoch 11/150\n",
      " - 0s - loss: 1.0521 - acc: 0.3400\n",
      "Epoch 12/150\n",
      " - 0s - loss: 1.0478 - acc: 0.3800\n",
      "Epoch 13/150\n",
      " - 0s - loss: 1.0437 - acc: 0.3500\n",
      "Epoch 14/150\n",
      " - 0s - loss: 1.0405 - acc: 0.3400\n",
      "Epoch 15/150\n",
      " - 0s - loss: 1.0373 - acc: 0.3400\n",
      "Epoch 16/150\n",
      " - 0s - loss: 1.0346 - acc: 0.3400\n",
      "Epoch 17/150\n",
      " - 0s - loss: 1.0319 - acc: 0.3400\n",
      "Epoch 18/150\n",
      " - 0s - loss: 1.0289 - acc: 0.3400\n",
      "Epoch 19/150\n",
      " - 0s - loss: 1.0262 - acc: 0.3400\n",
      "Epoch 20/150\n",
      " - 0s - loss: 1.0232 - acc: 0.3400\n",
      "Epoch 21/150\n",
      " - 0s - loss: 1.0201 - acc: 0.3400\n",
      "Epoch 22/150\n",
      " - 0s - loss: 1.0173 - acc: 0.3400\n",
      "Epoch 23/150\n",
      " - 0s - loss: 1.0145 - acc: 0.3400\n",
      "Epoch 24/150\n",
      " - 0s - loss: 1.0116 - acc: 0.3400\n",
      "Epoch 25/150\n",
      " - 0s - loss: 1.0089 - acc: 0.3400\n",
      "Epoch 26/150\n",
      " - 0s - loss: 1.0058 - acc: 0.3400\n",
      "Epoch 27/150\n",
      " - 0s - loss: 1.0029 - acc: 0.3400\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.9998 - acc: 0.3400\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.9968 - acc: 0.3400\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.9938 - acc: 0.3400\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.9913 - acc: 0.3400\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.9881 - acc: 0.3400\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.9851 - acc: 0.3400\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.9819 - acc: 0.3400\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.9788 - acc: 0.3400\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.9763 - acc: 0.3400\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.9726 - acc: 0.3400\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.9695 - acc: 0.3400\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.9665 - acc: 0.3400\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.9635 - acc: 0.3400\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.9607 - acc: 0.3400\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.9574 - acc: 0.3400\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.9542 - acc: 0.3500\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.9515 - acc: 0.3500\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.9481 - acc: 0.3500\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.9449 - acc: 0.3400\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.9419 - acc: 0.3400\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.9387 - acc: 0.3400\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.9356 - acc: 0.3500\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.9324 - acc: 0.3500\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.9291 - acc: 0.3500\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.9260 - acc: 0.3500\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.9229 - acc: 0.3600\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.9198 - acc: 0.3600\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.9166 - acc: 0.3600\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.9136 - acc: 0.3800\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.9104 - acc: 0.3800\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.9075 - acc: 0.3800\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.9044 - acc: 0.3800\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.9015 - acc: 0.3800\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.8983 - acc: 0.3800\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.8957 - acc: 0.3800\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.8927 - acc: 0.3800\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.8897 - acc: 0.3800\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.8867 - acc: 0.3800\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.8837 - acc: 0.3800\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.8810 - acc: 0.3800\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.8788 - acc: 0.3800\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.8753 - acc: 0.3900\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.8724 - acc: 0.4000\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.8694 - acc: 0.4100\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.8670 - acc: 0.4200\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.8639 - acc: 0.4200\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.8611 - acc: 0.4300\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.8584 - acc: 0.4400\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.8557 - acc: 0.4800\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.8531 - acc: 0.4800\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.8502 - acc: 0.5000\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.8477 - acc: 0.5300\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.8448 - acc: 0.5600\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.8420 - acc: 0.5700\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.8403 - acc: 0.5800\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.8379 - acc: 0.6100\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.8358 - acc: 0.6000\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.8338 - acc: 0.6100\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.8313 - acc: 0.6300\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.8283 - acc: 0.6400\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.8246 - acc: 0.6200\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.8217 - acc: 0.6300\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.8187 - acc: 0.6200\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.8161 - acc: 0.6300\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.8134 - acc: 0.6400\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.8105 - acc: 0.6300\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.8078 - acc: 0.6500\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.8051 - acc: 0.6500\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.8025 - acc: 0.6600\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.8000 - acc: 0.6700\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.7974 - acc: 0.6700\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.7949 - acc: 0.6400\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.7924 - acc: 0.6400\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.7904 - acc: 0.6700\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.7874 - acc: 0.6700\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.7850 - acc: 0.6500\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.7829 - acc: 0.6500\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.7803 - acc: 0.6500\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.7777 - acc: 0.6700\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.7756 - acc: 0.6800\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.7730 - acc: 0.6800\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.7707 - acc: 0.6800\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.7682 - acc: 0.6800\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.7659 - acc: 0.6800\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.7636 - acc: 0.6700\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.7614 - acc: 0.6700\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.7592 - acc: 0.6700\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.7570 - acc: 0.6700\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.7541 - acc: 0.6800\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.7516 - acc: 0.6900\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.7492 - acc: 0.7000\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.7476 - acc: 0.7000\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.7453 - acc: 0.7000\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.7427 - acc: 0.7000\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.7409 - acc: 0.7200\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.7385 - acc: 0.7200\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.7362 - acc: 0.7300\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.7340 - acc: 0.7200\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.7317 - acc: 0.7000\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.7291 - acc: 0.7000\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.7269 - acc: 0.7000\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.7249 - acc: 0.6900\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.7226 - acc: 0.6900\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.7204 - acc: 0.7000\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.7186 - acc: 0.7000\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.7165 - acc: 0.7000\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.7142 - acc: 0.7000\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.7121 - acc: 0.7000\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.7101 - acc: 0.7200\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.7081 - acc: 0.7200\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.7066 - acc: 0.7300\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.7045 - acc: 0.7300\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.7026 - acc: 0.7400\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.7010 - acc: 0.7600\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.7000 - acc: 0.7800\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.6990 - acc: 0.8400\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.6976 - acc: 0.8500\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.6955 - acc: 0.8500\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.6937 - acc: 0.8500\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.6909 - acc: 0.8500\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.6877 - acc: 0.8200\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.6849 - acc: 0.7700\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.6840 - acc: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e8e6d5d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=150,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets feed scaled_X_test to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05254806, 0.42669287, 0.520759  ],\n",
       "       [0.43990028, 0.33372506, 0.22637472],\n",
       "       [0.00335962, 0.27071404, 0.72592634],\n",
       "       [0.04864199, 0.40521955, 0.54613847],\n",
       "       [0.03192015, 0.40185496, 0.56622493],\n",
       "       [0.45744765, 0.3269463 , 0.21560612],\n",
       "       [0.09933446, 0.43092754, 0.46973792],\n",
       "       [0.01350869, 0.31147584, 0.6750155 ],\n",
       "       [0.03589595, 0.42454332, 0.53956074],\n",
       "       [0.08191957, 0.44188303, 0.47619742],\n",
       "       [0.0215238 , 0.33899242, 0.6394837 ],\n",
       "       [0.47055012, 0.3109637 , 0.2184862 ],\n",
       "       [0.46800366, 0.31474876, 0.21724758],\n",
       "       [0.47080058, 0.31092787, 0.21827155],\n",
       "       [0.47831672, 0.29915538, 0.22252785],\n",
       "       [0.04091027, 0.37896746, 0.58012223],\n",
       "       [0.01211863, 0.31205454, 0.67582685],\n",
       "       [0.08983364, 0.45533413, 0.45483214],\n",
       "       [0.06249768, 0.425315  , 0.5121873 ],\n",
       "       [0.01309927, 0.3228209 , 0.66407984],\n",
       "       [0.47611538, 0.3031969 , 0.2206878 ],\n",
       "       [0.03124436, 0.3700364 , 0.5987193 ],\n",
       "       [0.46944743, 0.31091636, 0.21963614],\n",
       "       [0.01429568, 0.33109665, 0.65460765],\n",
       "       [0.00749906, 0.27639198, 0.716109  ],\n",
       "       [0.01360815, 0.31449205, 0.6718998 ],\n",
       "       [0.01345287, 0.35491422, 0.6316329 ],\n",
       "       [0.00986088, 0.2928354 , 0.6973037 ],\n",
       "       [0.4715126 , 0.30962247, 0.2188649 ],\n",
       "       [0.47314483, 0.307594  , 0.21926124],\n",
       "       [0.48573554, 0.28881255, 0.22545195],\n",
       "       [0.46862936, 0.30882102, 0.22254966],\n",
       "       [0.04401139, 0.40184125, 0.5541473 ],\n",
       "       [0.47795168, 0.30067313, 0.2213752 ],\n",
       "       [0.48053247, 0.29601306, 0.2234545 ],\n",
       "       [0.02148707, 0.37065664, 0.6078562 ],\n",
       "       [0.04527766, 0.39227825, 0.5624441 ],\n",
       "       [0.47331217, 0.30732405, 0.21936384],\n",
       "       [0.47834763, 0.29990125, 0.2217512 ],\n",
       "       [0.47892496, 0.29811928, 0.22295584],\n",
       "       [0.02701867, 0.36977682, 0.6032045 ],\n",
       "       [0.05240292, 0.38236687, 0.56523025],\n",
       "       [0.03529822, 0.38824677, 0.576455  ],\n",
       "       [0.47723475, 0.30076122, 0.222004  ],\n",
       "       [0.47122553, 0.30963913, 0.21913539],\n",
       "       [0.10837538, 0.46138075, 0.43024388],\n",
       "       [0.03153661, 0.3935563 , 0.5749071 ],\n",
       "       [0.02136336, 0.3506288 , 0.6280078 ],\n",
       "       [0.04445651, 0.40587556, 0.5496679 ],\n",
       "       [0.00708597, 0.25887945, 0.7340346 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_X_test)  ### this gives the soft probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 2, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0,\n",
       "       0, 1, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare predictions with y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0,  2, 13],\n",
       "       [ 0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00        19\\n           1       1.00      0.13      0.24        15\\n           2       0.55      1.00      0.71        16\\n\\n   micro avg       0.74      0.74      0.74        50\\n   macro avg       0.85      0.71      0.65        50\\nweighted avg       0.86      0.74      0.68        50\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NNbasicModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('NNbasicModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
